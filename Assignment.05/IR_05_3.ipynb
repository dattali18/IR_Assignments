{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHMFjd3GJ-lt"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dattali18/IR_Assignments/blob/main/Assignment.05/IR_05_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ahFoJQ1eJ_r-"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s13hnXy5KBD9",
        "outputId": "fce68a32-e338-4cbe-872f-0eb6fb810d04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Downloading pip-25.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IsZyCHaIJ-l3",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# download the files from github\n",
        "sentences_url = \"https://github.com/dattali18/IR_Assignments/blob/main/Assignment.05/data/sentences/sentences_classify.csv?raw=true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPlVRWc2J-l4",
        "outputId": "85593da4-5364-492f-f1b0-c1cdd22a323e",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files downloaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# download all the file into the same dir as the note book\n",
        "\n",
        "import urllib.request\n",
        "\n",
        "urllib.request.urlretrieve(sentences_url, 'sentences.csv')\n",
        "\n",
        "print(\"Files downloaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pandas\n",
        "\n",
        "df = pd.read_csv(\"sentences.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install transformers sentence-transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Load BERT model and tokenizer\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load SBERT model\n",
        "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Function to generate BERT embeddings\n",
        "def get_bert_embedding(sentence):\n",
        "    inputs = bert_tokenizer(sentence, return_tensors='pt', truncation=True, padding=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = bert_model(**inputs)\n",
        "    # Use the [CLS] token embedding as the sentence embedding\n",
        "    return outputs.last_hidden_state[:, 0, :].squeeze().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Function to generate SBERT embeddings\n",
        "def get_sbert_embedding(sentence):\n",
        "    return sbert_model.encode(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Generate BERT embeddings\n",
        "sentences_df['bert_embedding'] = sentences_df['sentence'].apply(get_bert_embedding)\n",
        "\n",
        "# Generate SBERT embeddings\n",
        "sentences_df['sbert_embedding'] = sentences_df['sentence'].apply(get_sbert_embedding)\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(sentences_df.head())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
