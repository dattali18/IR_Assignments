{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPbUceohYSS5ZC7k4Z1Mn6c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dattali18/IR_Assignments/blob/main/Assignment.04/IR_04_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6pced4vRuxi2"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip"
      ],
      "metadata": {
        "id": "jj93pSCZvsVf",
        "outputId": "99b2c653-7686-4b9c-92a3-be3e006d70a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy torch transformers datasets scikit-learn tqdm"
      ],
      "metadata": {
        "id": "jb7zHoPHuqdc",
        "outputId": "bf803ec5-6c99-47ef-ec94-7398eb9295a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "A6I-laazus3v"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "PxXBLEihuvKX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29b6c48e-6313-49e4-b1b4-5952ee2136ff"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "link = \"https://github.com/dattali18/IR_Assignments/blob/main/Assignment.04/sentences.csv?raw=true\"\n",
        "df = pd.read_csv(link)\n",
        "texts = df['sentence'].values\n",
        "labels = df['label'].values"
      ],
      "metadata": {
        "id": "wwsX-mx1uxCc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# take a subset of the df 100 from each of the 5 classes\n",
        "df = df.groupby('label').apply(lambda x: x.sample(n=500, random_state=42)).reset_index(drop=True)\n",
        "texts = df['sentence'].values\n",
        "labels = df['label'].values"
      ],
      "metadata": {
        "id": "JZXC6SlAvSkF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if the df contains 500 instances\n",
        "df.groupby('label').count()"
      ],
      "metadata": {
        "id": "vPMnvlnBvZVo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "906f563f-5d13-45d7-d7cd-e7e760e1663d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id  sentence  type\n",
              "label                     \n",
              "0      500       476   500\n",
              "1      500       500   500\n",
              "2      500       500   500\n",
              "3      500       500   500\n",
              "4      500       500   500"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce7304bd-fceb-42ff-bb1d-78bf187225cb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>500</td>\n",
              "      <td>476</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce7304bd-fceb-42ff-bb1d-78bf187225cb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ce7304bd-fceb-42ff-bb1d-78bf187225cb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ce7304bd-fceb-42ff-bb1d-78bf187225cb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6e917242-5968-4720-a29a-c917c4fdd359\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6e917242-5968-4720-a29a-c917c4fdd359')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6e917242-5968-4720-a29a-c917c4fdd359 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 500,\n        \"max\": 500,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          500\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 476,\n        \"max\": 500,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          500\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 500,\n        \"max\": 500,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          500\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    texts, labels, test_size=0.15, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "4pxDy1rzu8Jr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset class\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "id": "UtMHybZmu9qk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model class\n",
        "class SentimentClassifier(nn.Module):\n",
        "    def __init__(self, n_classes=5):\n",
        "        super().__init__()\n",
        "        self.bert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "        self.drop = nn.Dropout(0.3)\n",
        "        self.fc = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        output = self.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "        output = self.drop(output[0][:, 0, :])\n",
        "        return self.fc(output)"
      ],
      "metadata": {
        "id": "IbmuYOvvvAH-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize tokenizer and create datasets\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "train_dataset = SentimentDataset(train_texts, train_labels, tokenizer)\n",
        "val_dataset = SentimentDataset(val_texts, val_labels, tokenizer)"
      ],
      "metadata": {
        "id": "0z7Vey5DvCGt",
        "collapsed": true
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)"
      ],
      "metadata": {
        "id": "dkHzrNnBvFO_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model and move to GPU\n",
        "model = SentimentClassifier()\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "c1MFC0dHvFkk",
        "collapsed": true
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training parameters\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "n_epochs = 5"
      ],
      "metadata": {
        "id": "ewNVzsDsvHMN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "def train_model():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in tqdm(train_loader, desc='Training'):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(train_loader)"
      ],
      "metadata": {
        "id": "hJMIkoPYvIqR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation loop\n",
        "def evaluate_model():\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader, desc='Evaluating'):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            _, predictions = torch.max(outputs, dim=1)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = np.mean(np.array(all_predictions) == np.array(all_labels))\n",
        "    return total_loss / len(val_loader), accuracy"
      ],
      "metadata": {
        "id": "0whvSkilvKic"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "for epoch in range(n_epochs):\n",
        "    print(f'\\nEpoch {epoch + 1}/{n_epochs}')\n",
        "    train_loss = train_model()\n",
        "    val_loss, val_accuracy = evaluate_model()\n",
        "\n",
        "    print(f'Training Loss: {train_loss:.4f}')\n",
        "    print(f'Validation Loss: {val_loss:.4f}')\n",
        "    print(f'Validation Accuracy: {val_accuracy:.4f}')"
      ],
      "metadata": {
        "id": "cpiOlQj2vMnr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7af91124-624f-4475-ee97-c9f4bc3b45a3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 133/133 [00:26<00:00,  4.95it/s]\n",
            "Evaluating: 100%|██████████| 24/24 [00:01<00:00, 16.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.7387\n",
            "Validation Loss: 0.1756\n",
            "Validation Accuracy: 0.9493\n",
            "\n",
            "Epoch 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 133/133 [00:22<00:00,  5.79it/s]\n",
            "Evaluating: 100%|██████████| 24/24 [00:01<00:00, 16.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.1003\n",
            "Validation Loss: 0.1437\n",
            "Validation Accuracy: 0.9573\n",
            "\n",
            "Epoch 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 133/133 [00:23<00:00,  5.66it/s]\n",
            "Evaluating: 100%|██████████| 24/24 [00:01<00:00, 16.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.0402\n",
            "Validation Loss: 0.1156\n",
            "Validation Accuracy: 0.9680\n",
            "\n",
            "Epoch 4/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 133/133 [00:23<00:00,  5.54it/s]\n",
            "Evaluating: 100%|██████████| 24/24 [00:01<00:00, 13.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.0237\n",
            "Validation Loss: 0.1606\n",
            "Validation Accuracy: 0.9547\n",
            "\n",
            "Epoch 5/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 133/133 [00:24<00:00,  5.43it/s]\n",
            "Evaluating: 100%|██████████| 24/24 [00:01<00:00, 16.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.0076\n",
            "Validation Loss: 0.1725\n",
            "Validation Accuracy: 0.9627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "torch.save(model.state_dict(), 'sentiment_model_v2.pth')"
      ],
      "metadata": {
        "id": "Sp-87BU0vOih"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use the model for testing a sentence\n",
        "\n",
        "e1 = \"The Hamas terroriest have launch a rocket attack to major isreali cities\""
      ],
      "metadata": {
        "id": "e9eZxA8QJWmU"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# from transformers import DistilBertTokenizer\n",
        "\n",
        "# Assuming the SentimentClassifier class is already defined as provided\n",
        "\n",
        "# Initialize the model and tokenizer\n",
        "# model = SentimentClassifier()\n",
        "# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Function to classify a sentence and get probabilities\n",
        "def classify_sentence_prob(sentence):\n",
        "    # Tokenize the sentence\n",
        "    inputs = tokenizer(sentence, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
        "\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # Get the model's output\n",
        "    with torch.no_grad():\n",
        "        logits = model(inputs['input_ids'], inputs['attention_mask'])\n",
        "\n",
        "    # Apply softmax to get probabilities\n",
        "    probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
        "\n",
        "    return probabilities\n",
        "\n",
        "# Example usage\n",
        "# sentence = \"This is a sample sentence for classification.\"\n",
        "probabilities = classify_sentence_prob(e1)\n",
        "\n",
        "print(\"Probabilities for each class:\", probabilities)"
      ],
      "metadata": {
        "id": "G4EnWBM6KZ1Z",
        "outputId": "ae1b5421-09cf-456f-9362-0bd90b2276f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probabilities for each class: tensor([[7.5548e-05, 6.6228e-05, 8.5338e-05, 3.5502e-05, 9.9974e-01]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# from transformers import DistilBertTokenizer\n",
        "\n",
        "# Assuming the SentimentClassifier class is already defined as provided\n",
        "\n",
        "# Initialize the model and tokenizer\n",
        "# model = SentimentClassifier()\n",
        "# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Function to classify a sentence and get one-hot encoded vector\n",
        "def classify_sentence_class(sentence):\n",
        "    # Tokenize the sentence\n",
        "    inputs = tokenizer(sentence, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # Get the model's output\n",
        "    with torch.no_grad():\n",
        "        logits = model(inputs['input_ids'], inputs['attention_mask'])\n",
        "\n",
        "    # Apply softmax to get probabilities\n",
        "    probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
        "\n",
        "    # Get the predicted class (index of the max probability)\n",
        "    predicted_class = torch.argmax(probabilities, dim=1).item()\n",
        "\n",
        "    # Create a one-hot encoded vector\n",
        "    one_hot_vector = torch.zeros(probabilities.size(1))\n",
        "    one_hot_vector[predicted_class] = 1\n",
        "\n",
        "    return one_hot_vector\n",
        "\n",
        "# Example usage\n",
        "# sentence = \"This is a sample sentence for classification.\"\n",
        "one_hot_vector = classify_sentence_class(e1)\n",
        "\n",
        "print(\"One-hot encoded vector for the predicted class:\", one_hot_vector)"
      ],
      "metadata": {
        "id": "3KwwvWiDKhv9",
        "outputId": "d7b607e7-9e70-4027-ccca-fd3c3310b9cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-hot encoded vector for the predicted class: tensor([0., 0., 0., 0., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_to_class(one_hot_vector, map_class):\n",
        "    # Find the index of the maximum value in the one-hot encoded vector\n",
        "    class_index = torch.argmax(one_hot_vector).item()\n",
        "\n",
        "    # Get the string representation of the class from the map_class dictionary\n",
        "    class_string = map_class[class_index]\n",
        "\n",
        "    return class_string\n",
        "\n",
        "map_class = {0: 'pro-israeli', 1: 'pro-palestinan', 2: 'neutral', 3: 'anti-isreali', 4: 'anti-palestinian'}\n",
        "\n",
        "one_hot_to_class(one_hot_vector, map_class)"
      ],
      "metadata": {
        "id": "Asw64A3GKzxJ",
        "outputId": "210c5b7e-affa-4c93-efcf-6b64844751fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'anti-palestinian'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_sentence(sentence):\n",
        "    # Tokenize the sentence\n",
        "    inputs = tokenizer(sentence, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    # Get the model's output\n",
        "    with torch.no_grad():\n",
        "        logits = model(inputs['input_ids'], inputs['attention_mask'])\n",
        "\n",
        "    # Apply softmax to get probabilities\n",
        "    probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
        "\n",
        "    # get the str of the calss based on the one-hot-encoded vector\n",
        "    predicted_class = torch.argmax(probabilities, dim=1).item()\n",
        "\n",
        "    # Create a one-hot encoded vector\n",
        "    one_hot_vector = torch.zeros(probabilities.size(1))\n",
        "    one_hot_vector[predicted_class] = 1\n",
        "\n",
        "    map_class = {0: 'pro-israeli', 1: 'pro-palestinan', 2: 'neutral', 3: 'anti-isreali', 4: 'anti-palestinian'}\n",
        "\n",
        "\n",
        "    return probabilities, one_hot_to_class(one_hot_vector, map_class)"
      ],
      "metadata": {
        "id": "hOEdbtQ1PjxF"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the data from the github repository\n",
        "aj_url = \"https://github.com/dattali18/IR_Assignments/blob/main/Assignment.01/data/word/A_J_word.csv?raw=true\"\n",
        "bbc_url = \"https://github.com/dattali18/IR_Assignments/blob/main/Assignment.01/data/word/BBC_word.csv?raw=true\"\n",
        "jp_url = \"https://github.com/dattali18/IR_Assignments/blob/main/Assignment.01/data/word/J_P_word.csv?raw=true\"\n",
        "nyt_url = \"https://github.com/dattali18/IR_Assignments/blob/main/Assignment.01/data/word/NYT_word.csv?raw=true\""
      ],
      "metadata": {
        "id": "y-rYe1-sO1GS"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# load the data\n",
        "aj_df = pd.read_csv(aj_url)\n",
        "bbc_df = pd.read_csv(bbc_url)\n",
        "jp_df = pd.read_csv(jp_url)\n",
        "nyt_df = pd.read_csv(nyt_url)"
      ],
      "metadata": {
        "id": "6-iyagGzPARr"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    # Normalize all types of single and double quotation marks to standard forms\n",
        "    text = re.sub(r\"[‘’`]\", \"'\", text)  # Convert all single quote variations to '\n",
        "    text = re.sub(r\"[“”]\", '\"', text)  # Convert all double quote variations to \"\n",
        "\n",
        "    # remove any and all special characters since it will not be useful for our analysis\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
        "\n",
        "    return text\n",
        "\n",
        "def extract_all_sentences(df):\n",
        "    # this will return a dict with key the id of the article \"aj_1\" for example\n",
        "    # and a list of all the sentences in the article\n",
        "\n",
        "    all_sentences = []\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        text = row[\"document\"]\n",
        "        # TODO - ask gpt for a smarter sentence extratctor\n",
        "        sentences = re.split(r\"[.!?]\", text)\n",
        "        sentences = [sentence for sentence in sentences if sentence != \"\"]\n",
        "        # clean the sentences\n",
        "        sentences = [clean_text(sentence) for sentence in sentences]\n",
        "\n",
        "        # for all sentence in sentences add to df\n",
        "        for sentence in sentences:\n",
        "            all_sentences.append({\"id\": row[\"id\"], \"document\": sentence})\n",
        "\n",
        "    return all_sentences"
      ],
      "metadata": {
        "id": "gjF7BdHuPDzR"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aj_sentences = extract_all_sentences(aj_df)\n",
        "bbc_sentences = extract_all_sentences(bbc_df)\n",
        "jp_sentences = extract_all_sentences(jp_df)\n",
        "nyt_sentences = extract_all_sentences(nyt_df)"
      ],
      "metadata": {
        "id": "YJisu_ZOPGfu"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aj_df = pd.DataFrame(aj_sentences)\n",
        "bbc_df = pd.DataFrame(bbc_sentences)\n",
        "jp_df = pd.DataFrame(jp_sentences)\n",
        "nyt_df = pd.DataFrame(nyt_sentences)"
      ],
      "metadata": {
        "id": "NXNcXLmqPMsb"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(columns=[\"id\", \"document\", \"pro-israeli\", \"pro-palestinan\", \"neutral\", \"anti-isreali\", \"anti-palestinian\", \"majority_class\"])\n",
        "df = pd.concat([df, aj_df], ignore_index=True)\n",
        "df = pd.concat([df, bbc_df], ignore_index=True)\n",
        "df = pd.concat([df, jp_df], ignore_index=True)\n",
        "df = pd.concat([df, nyt_df], ignore_index=True)\n",
        "\n",
        "df[[\"pro-israeli\", \"pro-palestinan\", \"neutral\", \"anti-isreali\", \"anti-palestinian\"]] = 0\n",
        "df['majority_class'] = ''\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Ndw_7CKzPPCW",
        "outputId": "09baa413-7c7d-4a8d-83f8-3f11fe0d4a43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     id                                           document  pro-israeli  \\\n",
              "0  aj_1  pope renews call for gaza ceasefire  release o...            0   \n",
              "1  aj_1   pope francis has renewed calls for an immedia...            0   \n",
              "2  aj_2  biden is still the best us president israel co...            0   \n",
              "3  aj_2   united states president ronald reagans order ...            0   \n",
              "4  aj_3  israeli air strikes continue across gaza as tr...            0   \n",
              "\n",
              "   pro-palestinan  neutral  anti-isreali  anti-palestinian majority_class  \n",
              "0               0        0             0                 0                 \n",
              "1               0        0             0                 0                 \n",
              "2               0        0             0                 0                 \n",
              "3               0        0             0                 0                 \n",
              "4               0        0             0                 0                 "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-733f220c-c84a-47c4-bfdf-54d6a57f0bb8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>pro-israeli</th>\n",
              "      <th>pro-palestinan</th>\n",
              "      <th>neutral</th>\n",
              "      <th>anti-isreali</th>\n",
              "      <th>anti-palestinian</th>\n",
              "      <th>majority_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aj_1</td>\n",
              "      <td>pope renews call for gaza ceasefire  release o...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>aj_1</td>\n",
              "      <td>pope francis has renewed calls for an immedia...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>aj_2</td>\n",
              "      <td>biden is still the best us president israel co...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>aj_2</td>\n",
              "      <td>united states president ronald reagans order ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>aj_3</td>\n",
              "      <td>israeli air strikes continue across gaza as tr...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-733f220c-c84a-47c4-bfdf-54d6a57f0bb8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-733f220c-c84a-47c4-bfdf-54d6a57f0bb8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-733f220c-c84a-47c4-bfdf-54d6a57f0bb8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8d62d235-819e-49bd-9446-7b5dc9344cfb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8d62d235-819e-49bd-9446-7b5dc9344cfb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8d62d235-819e-49bd-9446-7b5dc9344cfb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 48877,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2346,\n        \"samples\": [\n          \"jp_257\",\n          \"bbc_70\",\n          \"nyt_251\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"document\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39712,\n        \"samples\": [\n          \" The  ldquo  battle with the enemy must continue on all fronts until the liberation of the holy sites and the Arab and Islamic lands   rdquo  it said in a statement \",\n          \" The planned road will allow Israel to cut the West Bank in two  build E1 and the separation barrier  and close the door on the possibility of developing a sustainable Palestinian state \",\n          \" mr salha added   if we evacuate  these patients will be lost  they will not get the health services they need \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pro-israeli\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pro-palestinan\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"neutral\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"anti-isreali\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"anti-palestinian\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"majority_class\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rename document to sentnce in df\n",
        "\n",
        "df = df.rename(columns={\"document\": \"sentence\"})"
      ],
      "metadata": {
        "id": "nMv2OWHiSErL"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# now we wil use the model to classify each sentences for each article\n",
        "# and we will classify the article based on the majority of the sentences\n",
        "\n",
        "# TODO: load the model\n",
        "\n",
        "# df is the new dataframe with id, class1, ..., calss5, majority_class\n",
        "# the classi will contain the number of sentences in the article that belong to that class\n",
        "\n",
        "# loop through every items in df\n",
        "for index, row in df.iterrows():\n",
        "  sentence = row['sentence']\n",
        "\n",
        "  probs, cls = classify_sentence(sentence)\n",
        "  # put the values in the df\n",
        "  df.at[index, 'majority_class'] = cls\n",
        "  # unpack the values in probs (len 5) to the 5 classes of [\"pro-israeli\", \"pro-palestinan\", \"neutral\", \"anti-isreali\", \"anti-palestinian\"]\n",
        "  # map index to key\n",
        "  map_class = {0: 'pro-israeli', 1: 'pro-palestinan', 2: 'neutral', 3: 'anti-isreali', 4: 'anti-palestinian'}\n",
        "\n",
        "  for i in range(5):\n",
        "    df.at[index, map_class[i]] = probs[0][i].item()\n",
        "\n",
        "  # print at interval of 100 indexs\n",
        "  if index % 100 == 0:\n",
        "    print(f\"processing index {index}\")\n",
        "\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "QBeA1JB_PXEK",
        "outputId": "c0a06929-9970-4d41-cceb-873b9a81535c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing index 0\n",
            "processing index 100\n",
            "processing index 200\n",
            "processing index 300\n",
            "processing index 400\n",
            "processing index 500\n",
            "processing index 600\n",
            "processing index 700\n",
            "processing index 800\n",
            "processing index 900\n",
            "processing index 1000\n",
            "processing index 1100\n",
            "processing index 1200\n",
            "processing index 1300\n",
            "processing index 1400\n",
            "processing index 1500\n",
            "processing index 1600\n",
            "processing index 1700\n",
            "processing index 1800\n",
            "processing index 1900\n",
            "processing index 2000\n",
            "processing index 2100\n",
            "processing index 2200\n",
            "processing index 2300\n",
            "processing index 2400\n",
            "processing index 2500\n",
            "processing index 2600\n",
            "processing index 2700\n",
            "processing index 2800\n",
            "processing index 2900\n",
            "processing index 3000\n",
            "processing index 3100\n",
            "processing index 3200\n",
            "processing index 3300\n",
            "processing index 3400\n",
            "processing index 3500\n",
            "processing index 3600\n",
            "processing index 3700\n",
            "processing index 3800\n",
            "processing index 3900\n",
            "processing index 4000\n",
            "processing index 4100\n",
            "processing index 4200\n",
            "processing index 4300\n",
            "processing index 4400\n",
            "processing index 4500\n",
            "processing index 4600\n",
            "processing index 4700\n",
            "processing index 4800\n",
            "processing index 4900\n",
            "processing index 5000\n",
            "processing index 5100\n",
            "processing index 5200\n",
            "processing index 5300\n",
            "processing index 5400\n",
            "processing index 5500\n",
            "processing index 5600\n",
            "processing index 5700\n",
            "processing index 5800\n",
            "processing index 5900\n",
            "processing index 6000\n",
            "processing index 6100\n",
            "processing index 6200\n",
            "processing index 6300\n",
            "processing index 6400\n",
            "processing index 6500\n",
            "processing index 6600\n",
            "processing index 6700\n",
            "processing index 6800\n",
            "processing index 6900\n",
            "processing index 7000\n",
            "processing index 7100\n",
            "processing index 7200\n",
            "processing index 7300\n",
            "processing index 7400\n",
            "processing index 7500\n",
            "processing index 7600\n",
            "processing index 7700\n",
            "processing index 7800\n",
            "processing index 7900\n",
            "processing index 8000\n",
            "processing index 8100\n",
            "processing index 8200\n",
            "processing index 8300\n",
            "processing index 8400\n",
            "processing index 8500\n",
            "processing index 8600\n",
            "processing index 8700\n",
            "processing index 8800\n",
            "processing index 8900\n",
            "processing index 9000\n",
            "processing index 9100\n",
            "processing index 9200\n",
            "processing index 9300\n",
            "processing index 9400\n",
            "processing index 9500\n",
            "processing index 9600\n",
            "processing index 9700\n",
            "processing index 9800\n",
            "processing index 9900\n",
            "processing index 10000\n",
            "processing index 10100\n",
            "processing index 10200\n",
            "processing index 10300\n",
            "processing index 10400\n",
            "processing index 10500\n",
            "processing index 10600\n",
            "processing index 10700\n",
            "processing index 10800\n",
            "processing index 10900\n",
            "processing index 11000\n",
            "processing index 11100\n",
            "processing index 11200\n",
            "processing index 11300\n",
            "processing index 11400\n",
            "processing index 11500\n",
            "processing index 11600\n",
            "processing index 11700\n",
            "processing index 11800\n",
            "processing index 11900\n",
            "processing index 12000\n",
            "processing index 12100\n",
            "processing index 12200\n",
            "processing index 12300\n",
            "processing index 12400\n",
            "processing index 12500\n",
            "processing index 12600\n",
            "processing index 12700\n",
            "processing index 12800\n",
            "processing index 12900\n",
            "processing index 13000\n",
            "processing index 13100\n",
            "processing index 13200\n",
            "processing index 13300\n",
            "processing index 13400\n",
            "processing index 13500\n",
            "processing index 13600\n",
            "processing index 13700\n",
            "processing index 13800\n",
            "processing index 13900\n",
            "processing index 14000\n",
            "processing index 14100\n",
            "processing index 14200\n",
            "processing index 14300\n",
            "processing index 14400\n",
            "processing index 14500\n",
            "processing index 14600\n",
            "processing index 14700\n",
            "processing index 14800\n",
            "processing index 14900\n",
            "processing index 15000\n",
            "processing index 15100\n",
            "processing index 15200\n",
            "processing index 15300\n",
            "processing index 15400\n",
            "processing index 15500\n",
            "processing index 15600\n",
            "processing index 15700\n",
            "processing index 15800\n",
            "processing index 15900\n",
            "processing index 16000\n",
            "processing index 16100\n",
            "processing index 16200\n",
            "processing index 16300\n",
            "processing index 16400\n",
            "processing index 16500\n",
            "processing index 16600\n",
            "processing index 16700\n",
            "processing index 16800\n",
            "processing index 16900\n",
            "processing index 17000\n",
            "processing index 17100\n",
            "processing index 17200\n",
            "processing index 17300\n",
            "processing index 17400\n",
            "processing index 17500\n",
            "processing index 17600\n",
            "processing index 17700\n",
            "processing index 17800\n",
            "processing index 17900\n",
            "processing index 18000\n",
            "processing index 18100\n",
            "processing index 18200\n",
            "processing index 18300\n",
            "processing index 18400\n",
            "processing index 18500\n",
            "processing index 18600\n",
            "processing index 18700\n",
            "processing index 18800\n",
            "processing index 18900\n",
            "processing index 19000\n",
            "processing index 19100\n",
            "processing index 19200\n",
            "processing index 19300\n",
            "processing index 19400\n",
            "processing index 19500\n",
            "processing index 19600\n",
            "processing index 19700\n",
            "processing index 19800\n",
            "processing index 19900\n",
            "processing index 20000\n",
            "processing index 20100\n",
            "processing index 20200\n",
            "processing index 20300\n",
            "processing index 20400\n",
            "processing index 20500\n",
            "processing index 20600\n",
            "processing index 20700\n",
            "processing index 20800\n",
            "processing index 20900\n",
            "processing index 21000\n",
            "processing index 21100\n",
            "processing index 21200\n",
            "processing index 21300\n",
            "processing index 21400\n",
            "processing index 21500\n",
            "processing index 21600\n",
            "processing index 21700\n",
            "processing index 21800\n",
            "processing index 21900\n",
            "processing index 22000\n",
            "processing index 22100\n",
            "processing index 22200\n",
            "processing index 22300\n",
            "processing index 22400\n",
            "processing index 22500\n",
            "processing index 22600\n",
            "processing index 22700\n",
            "processing index 22800\n",
            "processing index 22900\n",
            "processing index 23000\n",
            "processing index 23100\n",
            "processing index 23200\n",
            "processing index 23300\n",
            "processing index 23400\n",
            "processing index 23500\n",
            "processing index 23600\n",
            "processing index 23700\n",
            "processing index 23800\n",
            "processing index 23900\n",
            "processing index 24000\n",
            "processing index 24100\n",
            "processing index 24200\n",
            "processing index 24300\n",
            "processing index 24400\n",
            "processing index 24500\n",
            "processing index 24600\n",
            "processing index 24700\n",
            "processing index 24800\n",
            "processing index 24900\n",
            "processing index 25000\n",
            "processing index 25100\n",
            "processing index 25200\n",
            "processing index 25300\n",
            "processing index 25400\n",
            "processing index 25500\n",
            "processing index 25600\n",
            "processing index 25700\n",
            "processing index 25800\n",
            "processing index 25900\n",
            "processing index 26000\n",
            "processing index 26100\n",
            "processing index 26200\n",
            "processing index 26300\n",
            "processing index 26400\n",
            "processing index 26500\n",
            "processing index 26600\n",
            "processing index 26700\n",
            "processing index 26800\n",
            "processing index 26900\n",
            "processing index 27000\n",
            "processing index 27100\n",
            "processing index 27200\n",
            "processing index 27300\n",
            "processing index 27400\n",
            "processing index 27500\n",
            "processing index 27600\n",
            "processing index 27700\n",
            "processing index 27800\n",
            "processing index 27900\n",
            "processing index 28000\n",
            "processing index 28100\n",
            "processing index 28200\n",
            "processing index 28300\n",
            "processing index 28400\n",
            "processing index 28500\n",
            "processing index 28600\n",
            "processing index 28700\n",
            "processing index 28800\n",
            "processing index 28900\n",
            "processing index 29000\n",
            "processing index 29100\n",
            "processing index 29200\n",
            "processing index 29300\n",
            "processing index 29400\n",
            "processing index 29500\n",
            "processing index 29600\n",
            "processing index 29700\n",
            "processing index 29800\n",
            "processing index 29900\n",
            "processing index 30000\n",
            "processing index 30100\n",
            "processing index 30200\n",
            "processing index 30300\n",
            "processing index 30400\n",
            "processing index 30500\n",
            "processing index 30600\n",
            "processing index 30700\n",
            "processing index 30800\n",
            "processing index 30900\n",
            "processing index 31000\n",
            "processing index 31100\n",
            "processing index 31200\n",
            "processing index 31300\n",
            "processing index 31400\n",
            "processing index 31500\n",
            "processing index 31600\n",
            "processing index 31700\n",
            "processing index 31800\n",
            "processing index 31900\n",
            "processing index 32000\n",
            "processing index 32100\n",
            "processing index 32200\n",
            "processing index 32300\n",
            "processing index 32400\n",
            "processing index 32500\n",
            "processing index 32600\n",
            "processing index 32700\n",
            "processing index 32800\n",
            "processing index 32900\n",
            "processing index 33000\n",
            "processing index 33100\n",
            "processing index 33200\n",
            "processing index 33300\n",
            "processing index 33400\n",
            "processing index 33500\n",
            "processing index 33600\n",
            "processing index 33700\n",
            "processing index 33800\n",
            "processing index 33900\n",
            "processing index 34000\n",
            "processing index 34100\n",
            "processing index 34200\n",
            "processing index 34300\n",
            "processing index 34400\n",
            "processing index 34500\n",
            "processing index 34600\n",
            "processing index 34700\n",
            "processing index 34800\n",
            "processing index 34900\n",
            "processing index 35000\n",
            "processing index 35100\n",
            "processing index 35200\n",
            "processing index 35300\n",
            "processing index 35400\n",
            "processing index 35500\n",
            "processing index 35600\n",
            "processing index 35700\n",
            "processing index 35800\n",
            "processing index 35900\n",
            "processing index 36000\n",
            "processing index 36100\n",
            "processing index 36200\n",
            "processing index 36300\n",
            "processing index 36400\n",
            "processing index 36500\n",
            "processing index 36600\n",
            "processing index 36700\n",
            "processing index 36800\n",
            "processing index 36900\n",
            "processing index 37000\n",
            "processing index 37100\n",
            "processing index 37200\n",
            "processing index 37300\n",
            "processing index 37400\n",
            "processing index 37500\n",
            "processing index 37600\n",
            "processing index 37700\n",
            "processing index 37800\n",
            "processing index 37900\n",
            "processing index 38000\n",
            "processing index 38100\n",
            "processing index 38200\n",
            "processing index 38300\n",
            "processing index 38400\n",
            "processing index 38500\n",
            "processing index 38600\n",
            "processing index 38700\n",
            "processing index 38800\n",
            "processing index 38900\n",
            "processing index 39000\n",
            "processing index 39100\n",
            "processing index 39200\n",
            "processing index 39300\n",
            "processing index 39400\n",
            "processing index 39500\n",
            "processing index 39600\n",
            "processing index 39700\n",
            "processing index 39800\n",
            "processing index 39900\n",
            "processing index 40000\n",
            "processing index 40100\n",
            "processing index 40200\n",
            "processing index 40300\n",
            "processing index 40400\n",
            "processing index 40500\n",
            "processing index 40600\n",
            "processing index 40700\n",
            "processing index 40800\n",
            "processing index 40900\n",
            "processing index 41000\n",
            "processing index 41100\n",
            "processing index 41200\n",
            "processing index 41300\n",
            "processing index 41400\n",
            "processing index 41500\n",
            "processing index 41600\n",
            "processing index 41700\n",
            "processing index 41800\n",
            "processing index 41900\n",
            "processing index 42000\n",
            "processing index 42100\n",
            "processing index 42200\n",
            "processing index 42300\n",
            "processing index 42400\n",
            "processing index 42500\n",
            "processing index 42600\n",
            "processing index 42700\n",
            "processing index 42800\n",
            "processing index 42900\n",
            "processing index 43000\n",
            "processing index 43100\n",
            "processing index 43200\n",
            "processing index 43300\n",
            "processing index 43400\n",
            "processing index 43500\n",
            "processing index 43600\n",
            "processing index 43700\n",
            "processing index 43800\n",
            "processing index 43900\n",
            "processing index 44000\n",
            "processing index 44100\n",
            "processing index 44200\n",
            "processing index 44300\n",
            "processing index 44400\n",
            "processing index 44500\n",
            "processing index 44600\n",
            "processing index 44700\n",
            "processing index 44800\n",
            "processing index 44900\n",
            "processing index 45000\n",
            "processing index 45100\n",
            "processing index 45200\n",
            "processing index 45300\n",
            "processing index 45400\n",
            "processing index 45500\n",
            "processing index 45600\n",
            "processing index 45700\n",
            "processing index 45800\n",
            "processing index 45900\n",
            "processing index 46000\n",
            "processing index 46100\n",
            "processing index 46200\n",
            "processing index 46300\n",
            "processing index 46400\n",
            "processing index 46500\n",
            "processing index 46600\n",
            "processing index 46700\n",
            "processing index 46800\n",
            "processing index 46900\n",
            "processing index 47000\n",
            "processing index 47100\n",
            "processing index 47200\n",
            "processing index 47300\n",
            "processing index 47400\n",
            "processing index 47500\n",
            "processing index 47600\n",
            "processing index 47700\n",
            "processing index 47800\n",
            "processing index 47900\n",
            "processing index 48000\n",
            "processing index 48100\n",
            "processing index 48200\n",
            "processing index 48300\n",
            "processing index 48400\n",
            "processing index 48500\n",
            "processing index 48600\n",
            "processing index 48700\n",
            "processing index 48800\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     id                                           sentence  pro-israeli  \\\n",
              "0  aj_1  pope renews call for gaza ceasefire  release o...     0.999303   \n",
              "1  aj_1   pope francis has renewed calls for an immedia...     0.999188   \n",
              "2  aj_2  biden is still the best us president israel co...     0.000075   \n",
              "3  aj_2   united states president ronald reagans order ...     0.000434   \n",
              "4  aj_3  israeli air strikes continue across gaza as tr...     0.000137   \n",
              "\n",
              "   pro-palestinan   neutral  anti-isreali  anti-palestinian  majority_class  \n",
              "0        0.000086  0.000212      0.000310          0.000088     pro-israeli  \n",
              "1        0.000102  0.000255      0.000333          0.000122     pro-israeli  \n",
              "2        0.999781  0.000060      0.000051          0.000033  pro-palestinan  \n",
              "3        0.000097  0.000106      0.999193          0.000170    anti-isreali  \n",
              "4        0.000065  0.000929      0.998556          0.000313    anti-isreali  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-96dc601a-47e3-4cd1-9fa2-23a073e80145\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>pro-israeli</th>\n",
              "      <th>pro-palestinan</th>\n",
              "      <th>neutral</th>\n",
              "      <th>anti-isreali</th>\n",
              "      <th>anti-palestinian</th>\n",
              "      <th>majority_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aj_1</td>\n",
              "      <td>pope renews call for gaza ceasefire  release o...</td>\n",
              "      <td>0.999303</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>0.000212</td>\n",
              "      <td>0.000310</td>\n",
              "      <td>0.000088</td>\n",
              "      <td>pro-israeli</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>aj_1</td>\n",
              "      <td>pope francis has renewed calls for an immedia...</td>\n",
              "      <td>0.999188</td>\n",
              "      <td>0.000102</td>\n",
              "      <td>0.000255</td>\n",
              "      <td>0.000333</td>\n",
              "      <td>0.000122</td>\n",
              "      <td>pro-israeli</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>aj_2</td>\n",
              "      <td>biden is still the best us president israel co...</td>\n",
              "      <td>0.000075</td>\n",
              "      <td>0.999781</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>0.000051</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>pro-palestinan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>aj_2</td>\n",
              "      <td>united states president ronald reagans order ...</td>\n",
              "      <td>0.000434</td>\n",
              "      <td>0.000097</td>\n",
              "      <td>0.000106</td>\n",
              "      <td>0.999193</td>\n",
              "      <td>0.000170</td>\n",
              "      <td>anti-isreali</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>aj_3</td>\n",
              "      <td>israeli air strikes continue across gaza as tr...</td>\n",
              "      <td>0.000137</td>\n",
              "      <td>0.000065</td>\n",
              "      <td>0.000929</td>\n",
              "      <td>0.998556</td>\n",
              "      <td>0.000313</td>\n",
              "      <td>anti-isreali</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96dc601a-47e3-4cd1-9fa2-23a073e80145')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-96dc601a-47e3-4cd1-9fa2-23a073e80145 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-96dc601a-47e3-4cd1-9fa2-23a073e80145');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-afdd307b-ece7-4513-960a-a77cae8ef072\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-afdd307b-ece7-4513-960a-a77cae8ef072')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-afdd307b-ece7-4513-960a-a77cae8ef072 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 48877,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2346,\n        \"samples\": [\n          \"jp_257\",\n          \"bbc_70\",\n          \"nyt_251\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39712,\n        \"samples\": [\n          \" The  ldquo  battle with the enemy must continue on all fronts until the liberation of the holy sites and the Arab and Islamic lands   rdquo  it said in a statement \",\n          \" The planned road will allow Israel to cut the West Bank in two  build E1 and the separation barrier  and close the door on the possibility of developing a sustainable Palestinian state \",\n          \" mr salha added   if we evacuate  these patients will be lost  they will not get the health services they need \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pro-israeli\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.44137486576358603,\n        \"min\": 4.542115857475437e-05,\n        \"max\": 0.9996042847633362,\n        \"num_unique_values\": 24503,\n        \"samples\": [\n          0.9995299577713013,\n          0.002224728697910905,\n          0.00015149304817896336\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pro-palestinan\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2507756856226219,\n        \"min\": 3.034289511560928e-05,\n        \"max\": 0.9998089671134949,\n        \"num_unique_values\": 37857,\n        \"samples\": [\n          0.00013279551058076322,\n          0.00010428204404888675,\n          0.0027853287756443024\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"neutral\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2327270080130364,\n        \"min\": 3.699552689795382e-05,\n        \"max\": 0.9996482133865356,\n        \"num_unique_values\": 38759,\n        \"samples\": [\n          0.00010126251436304301,\n          0.000456433481303975,\n          0.9996308088302612\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"anti-isreali\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.27524896833636436,\n        \"min\": 2.851058707165066e-05,\n        \"max\": 0.9994750618934631,\n        \"num_unique_values\": 39389,\n        \"samples\": [\n          0.00037502270424738526,\n          0.0001472487347200513,\n          0.00023188797058537602\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"anti-palestinian\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23350077995127178,\n        \"min\": 2.6536814402788877e-05,\n        \"max\": 0.9997745156288147,\n        \"num_unique_values\": 38482,\n        \"samples\": [\n          0.00011754075967473909,\n          9.860022692009807e-05,\n          9.071394015336409e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"majority_class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"pro-palestinan\",\n          \"neutral\",\n          \"anti-isreali\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the df into a csv file\n",
        "\n",
        "\n",
        "df.to_csv(\"sentences_with_class.csv\", index=False)"
      ],
      "metadata": {
        "id": "6hPKLaROVIrD"
      },
      "execution_count": 35,
      "outputs": []
    }
  ]
}